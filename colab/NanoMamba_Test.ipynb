{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NanoMamba-Tiny Checkpoint Test\n",
    "\n",
    "**NanoMamba: Noise-Robust KWS with Spectral-Aware State Space Models (Interspeech 2026)**\n",
    "\n",
    "| Cell | Content | Time |\n",
    "|:----:|---------|:----:|\n",
    "| 1 | Setup + Download GSC V2 | ~3min |\n",
    "| 2 | Load checkpoint + Clean test | ~2min |\n",
    "| 3 | Noise robustness evaluation | ~10min |\n",
    "| 4 | Results visualization | instant |\n",
    "\n",
    "**Runtime > Change runtime type > GPU (T4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Cell 1: Setup + Download GSC V2\n",
    "import torch, os, sys, time\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Clone repo (checkpoints included)\n",
    "if not os.path.exists('/content/NanoMamba-Interspeech2026'):\n",
    "    !git clone https://github.com/DrJinHoChoi/NanoMamba-Interspeech2026.git /content/NanoMamba-Interspeech2026\n",
    "\n",
    "%cd /content/NanoMamba-Interspeech2026\n",
    "\n",
    "# Verify checkpoint exists\n",
    "ckpt_path = 'checkpoints_full/NanoMamba-Tiny/best.pt'\n",
    "assert os.path.exists(ckpt_path), f\"Checkpoint not found: {ckpt_path}\"\n",
    "print(f\"Checkpoint found: {ckpt_path} ({os.path.getsize(ckpt_path)/1024:.1f} KB)\")\n",
    "\n",
    "# Download Google Speech Commands V2\n",
    "DATA_DIR = './data'\n",
    "GSC_DIR = os.path.join(DATA_DIR, 'SpeechCommands', 'speech_commands_v0.02')\n",
    "\n",
    "if not os.path.exists(GSC_DIR):\n",
    "    print(\"\\nDownloading Google Speech Commands V2 (~2.3GB)...\")\n",
    "    os.makedirs(GSC_DIR, exist_ok=True)\n",
    "    !wget -q http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz -O /tmp/gsc_v2.tar.gz\n",
    "    !tar -xzf /tmp/gsc_v2.tar.gz -C {GSC_DIR}\n",
    "    !rm /tmp/gsc_v2.tar.gz\n",
    "    print(\"Download complete!\")\n",
    "else:\n",
    "    print(f\"GSC V2 already exists at {GSC_DIR}\")\n",
    "\n",
    "classes = [d for d in os.listdir(GSC_DIR)\n",
    "           if os.path.isdir(os.path.join(GSC_DIR, d)) and not d.startswith('_')]\n",
    "print(f\"Found {len(classes)} keyword classes\")\n",
    "print(\"\\nReady for testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Cell 2: Load Checkpoint + Clean Evaluation\n",
    "import torch\n",
    "import numpy as np\n",
    "from nanomamba import create_nanomamba_tiny\n",
    "from train_all_models import (\n",
    "    SpeechCommandsDataset, evaluate, GSC_LABELS_12\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 1. Create model and load checkpoint\n",
    "model = create_nanomamba_tiny(n_classes=12)\n",
    "ckpt = torch.load('checkpoints_full/NanoMamba-Tiny/best.pt',\n",
    "                   map_location=device, weights_only=True)\n",
    "missing, unexpected = model.load_state_dict(\n",
    "    ckpt['model_state_dict'], strict=False)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "params = sum(p.numel() for p in model.parameters())\n",
    "fp32_kb = params * 4 / 1024\n",
    "int8_kb = params * 1 / 1024\n",
    "\n",
    "print(f\"Model: NanoMamba-Tiny\")\n",
    "print(f\"  Parameters: {params:,}\")\n",
    "print(f\"  FP32 size: {fp32_kb:.1f} KB\")\n",
    "print(f\"  INT8 size: {int8_kb:.1f} KB\")\n",
    "print(f\"  Checkpoint epoch: {ckpt['epoch']}\")\n",
    "print(f\"  Checkpoint val_acc: {ckpt['val_acc']:.2f}%\")\n",
    "if missing:\n",
    "    print(f\"  Missing keys (using defaults): {missing}\")\n",
    "\n",
    "# 2. Load validation and test datasets\n",
    "print(\"\\nLoading datasets...\")\n",
    "val_dataset = SpeechCommandsDataset('./data', subset='validation', augment=False)\n",
    "test_dataset = SpeechCommandsDataset('./data', subset='testing', augment=False)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "# 3. Clean evaluation\n",
    "print(\"\\nEvaluating (clean)...\")\n",
    "t0 = time.time()\n",
    "val_acc, val_preds, val_labels = evaluate(model, val_loader, device)\n",
    "test_acc, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"  CLEAN ACCURACY RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  Validation: {val_acc:.2f}%\")\n",
    "print(f\"  Test:       {test_acc:.2f}%\")\n",
    "print(f\"  Eval time:  {elapsed:.1f}s\")\n",
    "\n",
    "# 4. Per-class accuracy\n",
    "print(f\"\\n  Per-class Test Accuracy:\")\n",
    "print(f\"  {'Class':<12} {'Correct':>8} {'Total':>8} {'Acc':>8}\")\n",
    "print(f\"  {'-'*40}\")\n",
    "for i, label in enumerate(GSC_LABELS_12):\n",
    "    mask = test_labels == i\n",
    "    total_i = mask.sum()\n",
    "    if total_i > 0:\n",
    "        correct_i = (test_preds[mask] == i).sum()\n",
    "        acc_i = 100.0 * correct_i / total_i\n",
    "        print(f\"  {label:<12} {correct_i:>8} {total_i:>8} {acc_i:>7.1f}%\")\n",
    "\n",
    "print(f\"\\n  Overall Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Cell 3: Noise Robustness Evaluation\n",
    "from train_all_models import evaluate_noisy, evaluate_noisy_per_class\n",
    "import json\n",
    "\n",
    "noise_types = ['factory', 'white', 'babble', 'street', 'pink']\n",
    "snr_levels = [-15, -10, -5, 0, 5, 10, 15]\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  NOISE ROBUSTNESS EVALUATION\")\n",
    "print(f\"  Model: NanoMamba-Tiny ({params:,} params)\")\n",
    "print(f\"  Noise types: {noise_types}\")\n",
    "print(f\"  SNR levels: {snr_levels} dB\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "noise_results = {}\n",
    "for noise_type in noise_types:\n",
    "    noise_results[noise_type] = {}\n",
    "    print(f\"\\n  {noise_type.upper()}:\")\n",
    "    for snr in snr_levels:\n",
    "        t0 = time.time()\n",
    "        acc = evaluate_noisy(model, val_loader, device,\n",
    "                             noise_type=noise_type, snr_db=snr)\n",
    "        elapsed = time.time() - t0\n",
    "        noise_results[noise_type][snr] = acc\n",
    "        print(f\"    SNR={snr:>4}dB: {acc:.2f}% ({elapsed:.1f}s)\")\n",
    "    noise_results[noise_type]['clean'] = val_acc\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"  SUMMARY TABLE\")\n",
    "print(f\"{'='*80}\")\n",
    "header = f\"  {'Noise':<10} | {'Clean':>7} | \" + \" | \".join(f\"{s:>5}dB\" for s in snr_levels)\n",
    "print(header)\n",
    "print(f\"  {'-'*len(header)}\")\n",
    "for noise_type in noise_types:\n",
    "    clean = noise_results[noise_type]['clean']\n",
    "    snrs = [noise_results[noise_type][s] for s in snr_levels]\n",
    "    row = f\"  {noise_type:<10} | {clean:>6.1f}% | \" + \" | \".join(f\"{s:>5.1f}%\" for s in snrs)\n",
    "    print(row)\n",
    "\n",
    "# Save results\n",
    "save_results = {\n",
    "    'model': 'NanoMamba-Tiny',\n",
    "    'params': params,\n",
    "    'checkpoint_epoch': ckpt['epoch'],\n",
    "    'clean_val_acc': val_acc,\n",
    "    'clean_test_acc': test_acc,\n",
    "    'noise_robustness': {}\n",
    "}\n",
    "for nt in noise_types:\n",
    "    save_results['noise_robustness'][nt] = {\n",
    "        str(k): v for k, v in noise_results[nt].items()\n",
    "    }\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "with open('results/nanomamba_tiny_test_results.json', 'w') as f:\n",
    "    json.dump(save_results, f, indent=2)\n",
    "print(f\"\\nResults saved to results/nanomamba_tiny_test_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Cell 4: Results Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.size'] = 12\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# --- Plot 1: Noise robustness curves ---\n",
    "ax1 = axes[0]\n",
    "colors = {'factory': '#e74c3c', 'white': '#3498db', 'babble': '#2ecc71',\n",
    "          'street': '#f39c12', 'pink': '#9b59b6'}\n",
    "markers = {'factory': 'o', 'white': 's', 'babble': '^', 'street': 'D', 'pink': 'v'}\n",
    "\n",
    "for noise_type in noise_types:\n",
    "    accs = [noise_results[noise_type][s] for s in snr_levels]\n",
    "    ax1.plot(snr_levels, accs,\n",
    "             color=colors[noise_type], marker=markers[noise_type],\n",
    "             linewidth=2, markersize=8, label=noise_type.capitalize())\n",
    "\n",
    "ax1.axhline(y=val_acc, color='gray', linestyle='--', alpha=0.5, label=f'Clean ({val_acc:.1f}%)')\n",
    "ax1.set_xlabel('SNR (dB)')\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.set_title(f'NanoMamba-Tiny ({params:,} params) - Noise Robustness')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([0, 100])\n",
    "\n",
    "# --- Plot 2: Per-class accuracy (clean) ---\n",
    "ax2 = axes[1]\n",
    "class_accs = []\n",
    "for i, label in enumerate(GSC_LABELS_12):\n",
    "    mask = test_labels == i\n",
    "    total_i = mask.sum()\n",
    "    if total_i > 0:\n",
    "        correct_i = (test_preds[mask] == i).sum()\n",
    "        class_accs.append(100.0 * correct_i / total_i)\n",
    "    else:\n",
    "        class_accs.append(0)\n",
    "\n",
    "bars = ax2.barh(GSC_LABELS_12, class_accs, color='#3498db', edgecolor='white')\n",
    "ax2.set_xlabel('Accuracy (%)')\n",
    "ax2.set_title(f'Per-Class Test Accuracy (Overall: {test_acc:.1f}%)')\n",
    "ax2.set_xlim([0, 100])\n",
    "for bar, acc in zip(bars, class_accs):\n",
    "    ax2.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "             f'{acc:.1f}%', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/nanomamba_tiny_test_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Plot saved to results/nanomamba_tiny_test_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Cell 5: Download Results\n",
    "!zip -r /content/nanomamba_tiny_test.zip results/\n",
    "\n",
    "from google.colab import files\n",
    "files.download('/content/nanomamba_tiny_test.zip')\n",
    "print(\"Results downloaded!\")"
   ]
  }
 ]
}