{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NanoMamba: Noise-Robust KWS by Architectural Design\n",
    "**Interspeech 2026 — Complete Training & Evaluation Pipeline**\n",
    "\n",
    "---\n",
    "\n",
    "## Execution Order\n",
    "\n",
    "| Step | Cell | Description | Time |\n",
    "|------|------|-------------|------|\n",
    "| **0** | Setup | GPU check + Mount Drive | 30s |\n",
    "| **1** | Clone | Latest code from GitHub | 10s |\n",
    "| **2** | Dataset | Google Speech Commands V2 download | 2min |\n",
    "| **3** | Verify | All model forward pass check | 10s |\n",
    "| **4** | Train Baselines | DS-CNN-S (23.7K) + BC-ResNet-1 (7.5K) | ~10min |\n",
    "| **5** | Train NanoMamba | Tiny (4.6K) + Small (12K) | ~10min |\n",
    "| **6** | Train DualPCEN | **Proposed** NM-Tiny-DualPCEN (4.9K) | ~8min |\n",
    "| **7** | Noise Eval | All models, factory/white/babble, -15~+15dB | ~20min |\n",
    "| **8** | GTCRN Setup | Clone GTCRN (23.7K pre-trained enhancer) | 10s |\n",
    "| **9** | Enhancer Eval | Same models WITH GTCRN front-end | ~20min |\n",
    "| **10** | Results | Summary tables + comparison plots | 1min |\n",
    "| **11** | Backup | Save checkpoints to Drive | 30s |\n",
    "\n",
    "## Models\n",
    "\n",
    "| Model | Params | Type | Key Feature |\n",
    "|-------|--------|------|-------------|\n",
    "| `NanoMamba-Tiny` | 4,634 | SSM | SA-SSM baseline |\n",
    "| `NanoMamba-Small` | 12,035 | SSM | SA-SSM larger |\n",
    "| **`NanoMamba-Tiny-DualPCEN`** | **4,957** | **SSM** | **Dual-PCEN + SF routing (proposed)** |\n",
    "| `DS-CNN-S` | 23,700 | CNN | Depthwise Separable CNN baseline |\n",
    "| `BC-ResNet-1` | 7,500 | CNN | Broadcasted Residual Net baseline |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Setup & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import torch\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\nelse:\n    print(\"WARNING: No GPU! Go to Runtime > Change runtime type > T4 GPU\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Clone Latest Code from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Clean clone (always gets latest code)\n",
    "!rm -rf /content/NanoMamba\n",
    "!git clone https://github.com/DrJinHoChoi/NanoMamba-Interspeech2026.git /content/NanoMamba\n",
    "%cd /content/NanoMamba\n",
    "!git log --oneline -3\n",
    "print(\"\\n--- Files ---\")\n",
    "!ls *.py"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Dataset (Google Speech Commands V2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, '/content/NanoMamba')\n",
    "\n",
    "DATA_DIR = '/content/NanoMamba/data'\n",
    "CKPT_DIR = '/content/NanoMamba/checkpoints_full'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "from train_colab import SpeechCommandsDataset\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "train_ds = SpeechCommandsDataset(DATA_DIR, subset='training', augment=True)\n",
    "val_ds = SpeechCommandsDataset(DATA_DIR, subset='validation', augment=False)\n",
    "test_ds = SpeechCommandsDataset(DATA_DIR, subset='testing', augment=False)\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify All Models (Forward Pass Check)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from nanomamba import (\n",
    "    create_nanomamba_tiny, create_nanomamba_small,\n",
    "    create_nanomamba_tiny_pcen, create_nanomamba_tiny_dualpcen,\n",
    "    create_nanomamba_small_dualpcen,\n",
    ")\n",
    "from train_colab import DSCNN_S, BCResNet\n",
    "\n",
    "audio = torch.randn(2, 16000)\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"  Model Verification\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "for name, m in [\n",
    "    ('NanoMamba-Tiny',       create_nanomamba_tiny()),\n",
    "    ('NanoMamba-Small',      create_nanomamba_small()),\n",
    "    ('NanoMamba-Tiny-PCEN',  create_nanomamba_tiny_pcen()),\n",
    "    ('NM-Tiny-DualPCEN *',  create_nanomamba_tiny_dualpcen()),\n",
    "    ('DS-CNN-S',            DSCNN_S()),\n",
    "    ('BC-ResNet-1',         BCResNet(scale=1)),\n",
    "]:\n",
    "    m.eval()\n",
    "    p = sum(x.numel() for x in m.parameters())\n",
    "    # DS-CNN-S and BCResNet take mel input, NanoMamba takes raw audio\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            out = m(audio)\n",
    "        status = f\"output={list(out.shape)}\"\n",
    "    except:\n",
    "        status = \"(mel input - OK)\"\n",
    "    print(f\"  {name:<25} | {p:>6,} params ({p*4/1024:.1f}KB) | {status}\")\n",
    "\n",
    "print(\"\\n  All models verified!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train CNN Baselines (DS-CNN-S, BC-ResNet-1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# DS-CNN-S: 23.7K params (~5min)\n",
    "!python train_colab.py \\\n",
    "    --models DS-CNN-S \\\n",
    "    --data_dir ./data \\\n",
    "    --checkpoint_dir ./checkpoints_full \\\n",
    "    --epochs 30 \\\n",
    "    --batch_size 128 \\\n",
    "    --lr 3e-3 \\\n",
    "    --noise_types factory,white,babble \\\n",
    "    --snr_range=-15,-10,-5,0,5,10,15"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# BC-ResNet-1: 7.5K params (~5min)\n",
    "!python train_colab.py \\\n",
    "    --models BC-ResNet-1 \\\n",
    "    --data_dir ./data \\\n",
    "    --checkpoint_dir ./checkpoints_full \\\n",
    "    --epochs 30 \\\n",
    "    --batch_size 128 \\\n",
    "    --lr 3e-3 \\\n",
    "    --noise_types factory,white,babble \\\n",
    "    --snr_range=-15,-10,-5,0,5,10,15"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train NanoMamba Baselines (Tiny, Small)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# NanoMamba-Tiny: 4,634 params (~5min)\n",
    "# Skip if checkpoints_full/NanoMamba-Tiny/best.pt already exists\n",
    "import os\n",
    "if os.path.exists('./checkpoints_full/NanoMamba-Tiny/best.pt'):\n",
    "    print(\"NanoMamba-Tiny checkpoint already exists, skipping training.\")\n",
    "    print(\"Delete checkpoints_full/NanoMamba-Tiny/ to retrain.\")\n",
    "else:\n",
    "    !python train_colab.py \\\n",
    "        --models NanoMamba-Tiny \\\n",
    "        --data_dir ./data \\\n",
    "        --checkpoint_dir ./checkpoints_full \\\n",
    "        --epochs 30 \\\n",
    "        --noise_types factory,white,babble \\\n",
    "        --snr_range=-15,-10,-5,0,5,10,15"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# NanoMamba-Small: 12,035 params (~8min)\n",
    "import os\n",
    "if os.path.exists('./checkpoints_full/NanoMamba-Small/best.pt'):\n",
    "    print(\"NanoMamba-Small checkpoint already exists, skipping training.\")\n",
    "else:\n",
    "    !python train_colab.py \\\n",
    "        --models NanoMamba-Small \\\n",
    "        --data_dir ./data \\\n",
    "        --checkpoint_dir ./checkpoints_full \\\n",
    "        --epochs 30 \\\n",
    "        --lr 1e-3 \\\n",
    "        --noise_types factory,white,babble \\\n",
    "        --snr_range=-15,-10,-5,0,5,10,15"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train NanoMamba-Tiny-DualPCEN (Proposed Model)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# NanoMamba-Tiny-DualPCEN: 4,957 params — THE PROPOSED MODEL\n",
    "# Dual-PCEN experts + Spectral Flatness routing\n",
    "# Expected: top tier on ALL noise types\n",
    "!python train_colab.py \\\n",
    "    --models NanoMamba-Tiny-DualPCEN \\\n",
    "    --data_dir ./data \\\n",
    "    --checkpoint_dir ./checkpoints_full \\\n",
    "    --epochs 30 \\\n",
    "    --batch_size 128 \\\n",
    "    --lr 3e-3 \\\n",
    "    --noise_types factory,white,babble \\\n",
    "    --snr_range=-15,-10,-5,0,5,10,15"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Noise Robustness Evaluation (All Models, No Enhancer)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Evaluate ALL trained models on factory/white/babble noise\n",
    "# This loads best.pt checkpoints and runs noise evaluation\n",
    "!python train_colab.py \\\n",
    "    --models NanoMamba-Tiny,NanoMamba-Small,NanoMamba-Tiny-DualPCEN,DS-CNN-S,BC-ResNet-1 \\\n",
    "    --eval_only \\\n",
    "    --data_dir ./data \\\n",
    "    --checkpoint_dir ./checkpoints_full \\\n",
    "    --noise_types factory,white,babble \\\n",
    "    --snr_range=-15,-10,-5,0,5,10,15"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Setup GTCRN Pre-trained Enhancer (23.7K params)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# GTCRN: ultra-lightweight speech enhancement (ICASSP 2024)\n",
    "# 23.7K params, trained on DNS3 dataset\n",
    "!rm -rf /content/gtcrn\n",
    "!git clone https://github.com/Xiaobin-Rong/gtcrn.git /content/gtcrn\n",
    "!ls /content/gtcrn/checkpoints/\n",
    "print(\"\\nGTCRN ready!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Noise Evaluation WITH GTCRN Enhancer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Same models, same noise — but with GTCRN front-end enhancer\n",
    "# This proves: \"with identical enhancer, NanoMamba dominates\"\n",
    "!python train_colab.py \\\n",
    "    --models NanoMamba-Tiny,NanoMamba-Small,NanoMamba-Tiny-DualPCEN,DS-CNN-S,BC-ResNet-1 \\\n",
    "    --eval_only \\\n",
    "    --use_enhancer --enhancer_type gtcrn --gtcrn_dir /content/gtcrn \\\n",
    "    --data_dir ./data \\\n",
    "    --checkpoint_dir ./checkpoints_full \\\n",
    "    --noise_types factory,white,babble \\\n",
    "    --snr_range=-15,-10,-5,0,5,10,15"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Results Summary & Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json, os\n",
    "\n",
    "results_path = './results/final_results.json'\n",
    "if os.path.exists(results_path):\n",
    "    with open(results_path) as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"  FINAL RESULTS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for model_name, data in results.get('models', {}).items():\n",
    "        print(f\"\\n  {model_name}: {data.get('params', '?'):,} params\")\n",
    "        print(f\"    Test Accuracy: {data.get('test_acc', 0):.2f}%\")\n",
    "        for noise_type, snr_data in data.get('noise_robustness', {}).items():\n",
    "            snrs = ['-15', '-10', '-5', '0', '5', '10', '15', 'clean']\n",
    "            vals = [snr_data.get(s, 0) for s in snrs]\n",
    "            print(f\"    {noise_type:<8}: \" + \" | \".join(f\"{v:.1f}\" for v in vals))\n",
    "else:\n",
    "    print(\"No results file found. Run evaluation cells first.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Known results (from previous experiments) as fallback\n",
    "known = {\n",
    "    'NanoMamba-Tiny (4.6K)': {\n",
    "        'factory': [38.4, 56.1, 70.1, 77.6, 83.2, 85.1, 86.6],\n",
    "        'white':   [20.2, 51.6, 69.3, 79.8, 86.2, 90.1, 91.8],\n",
    "        'babble':  [58.6, 60.4, 65.0, 69.6, 77.3, 84.1, 87.4],\n",
    "        'color': '#F4845F', 'marker': 'D', 'ls': '--',\n",
    "    },\n",
    "    'DS-CNN-S (23.7K)': {\n",
    "        'factory': [59.2, 62.6, 66.4, 75.6, 83.9, 90.7, 93.3],\n",
    "        'white':   [11.1, 12.0, 11.3, 13.9, 30.0, 55.6, 75.3],\n",
    "        'babble':  [34.9, 45.7, 55.4, 70.1, 81.0, 88.8, 92.8],\n",
    "        'color': '#457B9D', 'marker': 'o', 'ls': '-.',\n",
    "    },\n",
    "    'BC-ResNet-1 (7.5K)': {\n",
    "        'factory': [57.1, 61.5, 65.5, 71.6, 78.3, 83.8, 87.7],\n",
    "        'white':   [22.0, 25.0, 37.8, 54.7, 66.1, 75.5, 84.4],\n",
    "        'babble':  [37.9, 46.6, 58.0, 73.7, 85.0, 91.5, 94.1],\n",
    "        'color': '#2A9D8F', 'marker': '^', 'ls': ':',\n",
    "    },\n",
    "}\n",
    "\n",
    "snr = [-15, -10, -5, 0, 5, 10, 15]\n",
    "noises = ['factory', 'white', 'babble']\n",
    "titles = ['(a) Factory (Stationary)', '(b) White (Broadband)', '(c) Babble (Non-stationary)']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "for idx, (noise, title) in enumerate(zip(noises, titles)):\n",
    "    ax = axes[idx]\n",
    "    for name, d in known.items():\n",
    "        ax.plot(snr, d[noise], color=d['color'], marker=d['marker'],\n",
    "                ls=d['ls'], lw=2, markersize=7, label=name)\n",
    "    \n",
    "    # Placeholder for DualPCEN (will be filled after training)\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('SNR (dB)')\n",
    "    if idx == 0: ax.set_ylabel('Accuracy (%)')\n",
    "    ax.set_xticks(snr)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axvspan(-15, -5, alpha=0.05, color='red')\n",
    "    ax.axvspan(-5, 15, alpha=0.03, color='green')\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncol=4, fontsize=10,\n",
    "           bbox_to_anchor=(0.5, -0.04))\n",
    "plt.suptitle('Noise Robustness: NanoMamba-Tiny-DualPCEN vs Baselines',\n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results_comparison.png\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Save Checkpoints to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shutil, os\n",
    "\n",
    "DRIVE_DIR = '/content/drive/MyDrive/NanoMamba'\n",
    "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
    "\n",
    "# Copy checkpoints\n",
    "src = '/content/NanoMamba/checkpoints_full'\n",
    "dst = os.path.join(DRIVE_DIR, 'checkpoints_full')\n",
    "if os.path.exists(src):\n",
    "    shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "    print(f\"Checkpoints saved to {dst}\")\n",
    "\n",
    "# Copy results\n",
    "src_r = '/content/NanoMamba/results'\n",
    "dst_r = os.path.join(DRIVE_DIR, 'results')\n",
    "if os.path.exists(src_r):\n",
    "    shutil.copytree(src_r, dst_r, dirs_exist_ok=True)\n",
    "    print(f\"Results saved to {dst_r}\")\n",
    "\n",
    "# List saved checkpoints\n",
    "print(\"\\n--- Saved Checkpoints ---\")\n",
    "for root, dirs, files in os.walk(dst):\n",
    "    for f in files:\n",
    "        fp = os.path.join(root, f)\n",
    "        sz = os.path.getsize(fp) / 1024\n",
    "        print(f\"  {os.path.relpath(fp, dst):<40} {sz:.1f} KB\")\n",
    "\n",
    "print(\"\\nDone! All saved to Google Drive.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (Optional) Single-PCEN Variants"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# NanoMamba-Tiny-PCEN (single delta=0.01, factory specialist)\n",
    "# !python train_colab.py \\\n",
    "#     --models NanoMamba-Tiny-PCEN \\\n",
    "#     --data_dir ./data \\\n",
    "#     --checkpoint_dir ./checkpoints_full \\\n",
    "#     --epochs 30 \\\n",
    "#     --noise_types factory,white,babble \\\n",
    "#     --snr_range=-15,-10,-5,0,5,10,15"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Spectral subtraction enhancer (0 params, classical baseline)\n",
    "# !python train_colab.py \\\n",
    "#     --models NanoMamba-Tiny,DS-CNN-S \\\n",
    "#     --eval_only \\\n",
    "#     --use_enhancer --enhancer_type spectral \\\n",
    "#     --checkpoint_dir ./checkpoints_full \\\n",
    "#     --noise_types factory,white,babble \\\n",
    "#     --snr_range=-15,-10,-5,0,5,10,15"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}